\documentclass[]{elsarticle}
%\setlength{\marginparwidth}{0.5in}
\usepackage{amsmath,amssymb,amsthm,mathtools,bbm,booktabs,array,tikz,pifont,comment,multirow,url,graphicx}
\input FJHDef.tex

%Requires ApproxUnivariate_i.tex, univariate_integration_i.tex, ConesPaperSpikyquad.eps, ConesPaperFlukyquad.eps

\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\INT}{INT}
\DeclareMathOperator{\APP}{APP}
\DeclareMathOperator{\lin}{lin}
\DeclareMathOperator{\up}{up}
\DeclareMathOperator{\lo}{lo}
\DeclareMathOperator{\fix}{fix}
\DeclareMathOperator{\err}{err}
\DeclareMathOperator{\maxcost}{maxcost}
\DeclareMathOperator{\mincost}{mincost}
\newcommand{\herr}{\widehat{\err}}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}
\newtheorem{lem}{Lemma}
\newtheorem{cor}{Corollary}
\theoremstyle{definition}
\newtheorem{algo}{Algorithm}
\newtheorem{condit}{Condition}
%\newtheorem{assump}{Assumption}
\theoremstyle{remark}
\newtheorem{rem}{Remark}
\newcommand{\Fnorm}[1]{\abs{#1}_{\cf}}
\newcommand{\Ftnorm}[1]{\abs{#1}_{\tcf}}
\newcommand{\Gnorm}[1]{\norm[\cg]{#1}}
\newcommand{\flin}{f_{\text{\rm{lin}}}}
\newcommand{\FYnorm}[1]{\abs{#1}_{\cf_\cy}}
\newcommand{\Hnorm}[1]{\norm[\ch]{#1}}
\newcommand{\GYnorm}[1]{\abs{#1}_{\cg_\cy}}

\begin{document}
\section{The Basic Problem}
Consider real-valued input functions with domain $\cx=[a,b]$, where $a, b$ be two fixed real numbers with $a<b$. We want to do the function recovery and let $S$ be a solution operator.  Here we consider:
\begin{align*}
S: f \mapsto f, \qquad S:\cw^{2,\infty}[a,b] \to \cl_{\infty}[a,b].
\end{align*}
where
for all real numbers $\alpha, \beta$ with $\alpha < \beta$,
\begin{gather*}
\cw^{2,\infty}:=\cw^{2,\infty}[a,b], \qquad \cw^{2,\infty}[\alpha,\beta]:=\{f\in C[\alpha,\beta]: \bigl \lVert f''\bigr \rVert_{\infty,[\alpha,\beta]} <\infty\}, \\
\cl_{\infty}:=\cl_{\infty}[a,b], \qquad
\cl_{\infty}[\alpha,\beta]:=\cw^{0,\infty}[\alpha,\beta],\\
\bigl \lVert f'' \bigr \rVert_{[\alpha,\beta]} :=  \bigl \lVert f'' \bigr \rVert_{\infty,[\alpha,\beta]}, \qquad
\bigl \lVert f \bigr \rVert_{[\alpha,\beta]} :=  \bigl \lVert f \bigr \rVert_{\infty,[\alpha,\beta]}= \max_{\alpha \le x  \le \beta} \abs{f(x)}. \end{gather*}
Here we only consider infinity norm, so we omit sub index $\infty.$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Solving the Problems on Partitions}
For any interval $[\alpha, \ \beta] \subset [a, \ b]$, let let $f_{[\alpha, \ \beta]}$ denote $\cw^{2,\infty}$ restricted to the interval $[\alpha, \ \beta]$, i.e.,
\begin{equation*}
f_{[\alpha, \ \beta]}:[\alpha, \ \beta] \to \reals, \qquad f_{[\alpha, \ \beta]} :\vx \mapsto f(\vx).
\end{equation*}
Moreover, let $\cw^{2,\infty}[\alpha,\beta]$ denote the space of functions in $\cw^{2,\infty}$ restricted to the set interval $[\alpha, \ \beta]$.


For function recovery, these partitions take the form of subintervals of $[a,b]$:
\begin{gather*}
\ct=\{[\alpha,\beta] : a \le \alpha < \beta \le b \} \\
\cp=\{[t_0,t_1], [t_1,t_2],  \ldots, [t_{L-1},t_L]\}, \qquad a=t_0 < t_1 < \cdots < t_L=b.
\end{gather*}

For each $[\alpha,\beta]  \in \ct$,  we let
%\begin{itemize}
%\item For each $[\alpha,\beta]  \in \ct$, for simplicity of notation, we let
%$\bigl \lVert f'' \bigr \rVert_{[\alpha,\beta]} =  \bigl \lVert f''_{[\alpha,\beta] } \bigr \rVert_{\infty,[\alpha,\beta]}$.
%
%\item For each $\cy \in \ct$ there exists a solution operator $S(\cdot;\cy) : \cf \to \ch$, for which $S(f,\cy)$ is actually only a function of $f_{\cy}$.
%
%\end{itemize}
$  \bigl \lVert f'' \bigr \rVert_{[\alpha,\beta]} =  \bigl \lVert f''_{[\alpha,\beta] } \bigr \rVert_{\infty,[\alpha,\beta]}
$.

For partitions $\cp$, define algorithm and error
$$\vA(f;\cp)=\{A(f;[\alpha,\beta])\}_{[\alpha,\beta] \in \cp},  \qquad \veps_{\cp}=\{\varepsilon_{[\alpha,\beta]}\}_{[\alpha,\beta] \in \cp}.$$
$$
\vA(f;\cp)=\left\{
\begin{matrix}
A(f;[t_0,t_1]) & t_0 \le x \le t_1,\\
A(f;[t_1,t_2]) & t_1 \le x \le t_2,\\
\vdots & \vdots,\\
A(f;[t_{i-1},t_i]) & t_{i-1} \le x \le t_i,\\
\vdots & \vdots,\\
A(f;[t_{L-1},t_L]) & t_{L-1} \le x \le t_L.\\
\end{matrix}\right.
$$

Then our goal is
$$ \bigl \lVert f - \vA(f;\cp) \bigr \rVert \le  \bigl \lVert \veps_{\cp} \bigr \rVert < \varepsilon. $$
i.e.
$$ \bigl \lVert f- A(f;[\alpha,\beta]) \bigr \rVert_{[\alpha,\beta]}  \le  \varepsilon_{[\alpha,\beta]}  < \varepsilon \qquad \forall [\alpha,\beta] \in \cp.$$

%there exists a function $\Phi(\cdot; \cp): \cl_{\infty}^L \to \cl_{\infty}$ that combines the solutions defined on the subsets to reconstruct the true solution:
%\[
%S(f) = \Phi(\vS_{\cp}(f)), \quad \vS_{\cp}(f):= \{S(f; [\alpha, \beta])\}_{[\alpha, \beta] \in \cp}, \qquad \forall f \in \cw^{2,\infty}.
%\]
%Here $L=\abs{\cp}$ denotes the cardinality of $\cp$.
%\begin{itemize}
%\item There exists a pair of functions $(\tPhi,\err)(\cdot,\cdot; \cp): \ch^{\abs{\cp}} \times [0,\infty)^{\abs{\cp}} \to \ch \times [0,\infty)$ that combine approximate solutions defined on the subsets with error bounds to reconstruct an approximation to the true solution. If $\bignorm[\ch]{S(f;\cy) - \tS_{\cy}} \le \varepsilon_{\cy}$ for all $\cy \in \cp$, $\tvS_{\cp} := \{\tS_{\cy}\}_{\cy \in \cp}$,  and $\tveps_{\cp} := \{\tvareps_{\cy}\}_{\cy \in \cp}$, then
%\begin{equation*}
%\Hnorm{S(f) -  \tPhi(\tvS_{\cp}, \tveps_{\cp} ;\cp)} \le \err(\tvS_{\cp}, \tveps_{\cp} ;\cp) \qquad \forall f \in \cf.
%\end{equation*}
%Here $\abs{\cp}$ denotes the cardinality of $\cp$. Moreover,
%\[
%\err(\tvS_{\cp}, \vzero ;\cp) = 0, \qquad \tPhi(\tvS_{\cp}, \vzero ;\cp) = \Phi(\vS_{\cp}(f)) = S(f).
%\]
%\end{itemize}
%
%
%\begin{align*}
%& \Phi(\tvS_{\cp};\cp) = \tPhi(\tvS_{\cp},\veps_{\cp};\cp) = \sum_{l=1}^L  \tS_{[t_{l-1},t_l]}, \\
%&\err(\tvS_{\cp},\veps_{\cp};\cp) = \norm[\infty]{\veps_{\cp}}
%\end{align*}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithms}
Now we consider numerical algorithms for solving the problems on a subinterval $[\alpha, \beta]$ of $[a, b]$.

We use piecewise linear interpolation. The number of possible function values is $ n \in \naturals$, then we have
\begin{equation}
x_j= \alpha + (\beta-\alpha) \frac{j-1}{n-1}, \qquad j=1, \ldots, n,
\end{equation}
\begin{multline}
A_n(f;[\alpha,\beta]):=\\
\frac{n-1}{\beta-\alpha}\left[f(x_j)(x_{j+1}-x)+f(x_{j+1})(x-x_j)\right], \qquad  x_{j}\le x \le x_{j+1}
\end{multline}


The difference between $f$ and its linear spline can be bounded in terms of an integral involving the second derivative using integration by parts.  For $x \in [\alpha,\beta]$ it follows that
\begin{align}
f(x)-A_n(f;[\alpha,\beta])(x)
&= f(x) - \frac{n-1}{\beta-\alpha} \left[f(x_{j})(x_{j+1}-x) +f(x_{j+1})(x-x_j) \right] \nonumber\\
& = \frac{n-1}{\beta-\alpha}\int_{x_j}^{x_{j+1}} v_j(t,x) f''(t) \, \dif t, \label{fintermsfdoubprime}\\
f'(x)-A_n(f;[\alpha,\beta])'(x) & = \frac{n-1}{\beta-\alpha} \int_{x_j}^{x_{j+1}} \frac{\partial v_j}{\partial x}(t,x) f''(t) \, \dif t, \label{fprimeintermsfdoubprime}
\end{align}
where the continuous, piecewise differentiable kernel $v$ is defined as
\begin{equation*}
v_j(t,x) :=\begin{cases} (x_{j+1}-x)(x_j-t), & x_j\leq t\leq x,\\
(x-x_{j})(t- x_{j+1}), & x< t \leq x_{j+1},
\end{cases}.
\end{equation*}

To derive the error bounds for $A_{n}(f;[\alpha,\beta])$ we have:
\begin{align}
\norm[{[\alpha,\beta]}]{f-A_{n}(f;[\alpha,\beta])}
& \le \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n_i-1 }} \abs{f(x)-A_{n}(f;[\alpha,\beta])(x)}\nonumber\\
&= \frac{n-1}{\beta-\alpha} \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n-1 }}  \int_{x_j}^{x_{j+1}} \abs{v_j(t,x) f''(t)} \, \dif t \nonumber\\
&\le \frac{n-1}{\beta-\alpha} \norm[{[\alpha, \beta]}]{f''} \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n-1 }}  \int_{x_j}^{x_{j+1}} \abs{v_j(t,x)} \, \dif t\nonumber\\
&=\norm[{[\alpha, \beta]}]{f''} \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n-1 }}  \frac{(x-x_j)(x_{j+1}-x)}2 \nonumber \\
&= \frac{(\beta-\alpha)^2}{8(n-1)^2} \norm[{[\alpha, \beta]}]{f''}. \label{fdoubprimenorm}
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Functions in Cones}
The challenge in applying the error bounds for the non-adaptive function recovery algorithm is that $ \bigl \lVert f'' \bigr \rVert_{[\alpha,\beta]} $ is not known a priori.  Our approach is to assume that the input functions lie inside cones.

Let $\vtau_{\cp}=\{\tau_{[\alpha,\beta]}\}_{[\alpha,\beta] \in \cp}$.
For each $[\alpha, \ \beta] \in \ct$, there exists a norm $\norm[{[\alpha, \beta]}]{f'-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}}$ on space
$\cw^{2,\infty}[\alpha,\beta]$ weaker than $\norm[{[\alpha, \beta]}]{f''}$.
Here we define our cone condition
%\begin{itemize}
%
%\item For each $\cy \in \ct$ there exists a semi-norm $\GYnorm{\cdot}$ defined on the space $\cf_{\cy}$ that is weaker than $\FYnorm{\cdot}$.
%
%\item For a fixed function non-increasing $\tau: (0,1) \to (0,\infty)$, define the cone
%\begin{equation} \label{defcone}
%\cc_{\tau} = \{ f \in \cf : \FYnorm{f} \le \tau(\vol(\cy)) \GYnorm{f} \},
%\end{equation}
%where $\vol(\cy)$ denotes relative volume of $\cy$, i.e., the Lebesgue measure $\cy$ divided by the Lebesgue measure of $\cx$.
%
%\item For each $\cy \in \ct$ and each $n \in \cj$ there exists a non-adaptive approximation operator $G_n(\cdot;\cy) : \cf \to \ch$ that uses $n$ function values sampled only in $\cy$.
%
%\item There exists error bound functions $g_{\pm}:\cj \times \ct \to [0,\infty)$ such that $g(\cdot,\cy)$ is non-increasing, and
%\[
%-g_{-}(n,\cy) \FYnorm{f} \le \GYnorm{f} - G_n(f;\cy) \le g_{+}(n,\cy) \FYnorm{f}, \qquad \forall f \in \cf.
%\]
%Invoking the definition of the cone implies a two sided bound for  $\GYnorm{f}$ and $\GYnorm{f}$ in terms of $G_n(f;\cy)$:
%\begin{multline*}
%-\tau(\vol(\cy)) g_{-}(n,\cy) \GYnorm{f} \le \GYnorm{f} - G_n(f;\cy) \le \tau(\vol(\cy)) g_{+}(n,\cy) \GYnorm{f}, \\ \forall f \in \cc_{\tau}.
%\end{multline*}
%\begin{gather*}
%\frac{G_n(f;\cy)}{1+\tau(\vol(\cy)) g_{-}(n,\cy)} \le \GYnorm{f} \le \frac{G_n(f;\cy)}{1-\tau(\vol(\cy)) g_{+}(n,\cy)}, \quad \forall f \in \cc_{\tau}, \\
%\frac{\tau(\vol(\cy))G_n(f;\cy)}{1+\tau(\vol(\cy)) g_{-}(n,\cy)} \le \FYnorm{f} \le \frac{\tau(\vol(\cy))G_n(f;\cy)}{1-\tau(\vol(\cy)) g_{+}(n,\cy)}, \quad \forall f \in \cc_{\tau}.
%\end{gather*}
%
%\end{itemize}
\begin{equation} \label{coneappxdef}
\cc_{\vtau}:=\left\{f \in  \mathcal{W}^{2,\infty} : \norm[{[\alpha, \beta]}]{f''}\leq \frac{\tau_{[\alpha,\beta]}}{\beta-\alpha} \norm[{[\alpha, \beta]}]{f'-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}}\right\}.
\end{equation}
where $\tau_{[\alpha,\beta]}$ is a parameter depend on the length of interval $[\alpha,\beta]$.\\

Lower bound on $\norm[{[\alpha,\beta]}]{f''}$ can be derived similarly to the previous section using a centered difference.  Specifically, for $n_i \ge 3$,
\begin{equation} \label{Fnormappxalg}
F_{n}(f;[\alpha,\beta]) := \frac{(n-1)^2}{(\beta-\alpha)^2}\sup_{j=1, \ldots, n-2} \abs{f(x_j) - 2 f(x_{j+1})+f(x_{j+2})}.
\end{equation}
It follows using the H\"older's inequality that
\begin{align*}
F_{n}(f;[\alpha,\beta]) &= \frac{(n-1)^2}{(\beta-\alpha)^2}\sup_{j=1, \ldots, n-2}  \biggabs{\int_{x_j}^{x_{j+2}} \left[\frac{\beta-\alpha}{n-1} - \abs{x-x_{j+1}}\right] f''(x) \, \dif x} \\
&\le\frac{(n-1)^2}{(\beta-\alpha)^2}\sup_{j=1, \ldots, n-2}  \norm[{[\alpha,\beta]}]{f''} \int_{x_j}^{x_{j+2}} \abs{\frac{\beta-\alpha}{n-1} - \abs{x-x_{j+1}}} \, \dif x = \norm[{[\alpha,\beta]}]{f''}.
\end{align*}


Define\begin{multline}\label{estfirstderiv}
G_n(f;[\alpha,\beta]) := \norm[\infty]{A_{n}(f;[\alpha,\beta])' - A_2(f;[\alpha,\beta])'} \\
= \sup_{j=1, \ldots, n-1} \left|\frac{n-1}{\beta-\alpha} [f(x_{j+1})-f(x_j)]-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}\right|.
\end{multline}

Note $G_n(f;[\alpha,\beta])$ never overestimates $\norm[{[\alpha, \beta]}]{f'-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}}$ because

\begin{align*}
\norm[{[\alpha, \beta]}]{f'-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}} & = \norm[{[\alpha,\beta]}]{f'-A_2(f;[\alpha,\beta])'}\\
&= \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n-1 }} \abs{f'(x) - A_{2}(f;[\alpha,\beta])'(x)} \\
&\ge \sup_{j=1, \ldots, n-1} \frac{n-1}{\beta-\alpha}\int_{x_j}^{x_{j+1}} \abs{f'(x) - \frac{f(\beta)-f(\alpha)}{\beta-\alpha}} \, \dif x \\
&\ge \sup_{j=1, \ldots, n-1} \frac{n-1}{\beta-\alpha} \abs{\int_{x_j}^{x_{j+1}} \left[f'(x) -\frac{f(\beta)-f(\alpha)}{\beta-\alpha}\right] \, \dif x }\\
&= \sup_{j=1, \ldots, n-1} \frac{n-1}{\beta-\alpha} \abs{f(x_{j+1})-f(x_j) - \frac{f(\beta)-f(\alpha)}{\beta-\alpha}} \\
&=G_n(f;[\alpha,\beta]).
\end{align*}
%Thus, we have $g_{-}(n,[\alpha,\beta]):=0$.
%
%
%To find an upper bound on $\GYnorm{f} -G_n(f;[\alpha,\beta])$, note that
%\begin{equation*}
%\GYnorm{f} -G_n(f;[\alpha,\beta]) =\GYnorm{f}  - \GYnorm{A_{n}(f;[\alpha,\beta])} \le \GYnorm{f-A_{n}(f;[\alpha,\beta])} = \bignorm[\infty]{f' -A_{n_i}(f;[\alpha,\beta])'},
%\end{equation*}
Since $(f-A_{n}(f;[\alpha,\beta]))(x)$ vanishes for $x=\alpha,\beta$. Using \eqref{fprimeintermsfdoubprime} it then follows that
\begin{align*}
& \ \ \ \norm[{[\alpha, \beta]}]{f'-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}} -G_n(f;[\alpha,\beta]) \\
& \le \bignorm[\infty]{f' -A_{n}(f;[\alpha,\beta])'} \\
& = \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n-1 }} \abs{f'(x) -\frac{n-1}{\beta-\alpha}[f(x_{j+1})-f(x_j)]} \\
&=\frac{n-1}{\beta-\alpha} \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n_i-1 }} \abs{ \int_{x_j}^{x_{j+1}} \frac{\partial v_j}{\partial x}(t,x) f''(t) \, \dif t} \\
& \le \frac{n-1}{\beta-\alpha} \norm[{[\alpha, \beta]}]{f''} \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n_i-1 }} \int_{x_j}^{x_{j+1}} \abs{\frac{\partial v_j}{\partial x}(t,x)} \, \dif t \\
&=\frac{n-1}{\beta-\alpha}\norm[{[\alpha, \beta]}]{f''} \sup_{\substack{x_j \le x \le x_{j+1}\\ j=1, \ldots, n-1 }} \left \{\frac{(\beta-\alpha)^2}{2(n-1)^2} - (x-x_j)(x_{j+1}-x) \right\} \\
&= \frac{\beta-\alpha}{2(n-1)}\norm[{[\alpha, \beta]}]{f''}.
\end{align*}

Thus, we obtain if $ n>1+\tau_{[\alpha,\beta]}/2$
\begin{gather*}
G_n(f;[\alpha,\beta])\le \norm[{[\alpha, \beta]}]{f'-\frac{f(\beta)-f(\alpha)}{\beta-\alpha}} \le \frac{G_n(f;[\alpha,\beta])}{1-\tau_{[\alpha,\beta]}/(2n-2)} \quad \forall f \in \cc_{\vtau}.
\end{gather*}

Therefore, we obtain
\begin{align*}
& F_n(f;[\alpha,\beta]) \le \norm[{[\alpha,\beta]}]{f''} \le \frac{\tau_{[\alpha,\beta]}}{(\beta-\alpha)}\cdot\frac{G_n(f;[\alpha,\beta])}{1-\tau_{[\alpha,\beta]}/(2n-2)} \\
\Rightarrow
&\tau_{\min,n} =  \frac{F_{n}(f;[\alpha,\beta])}{G_{n}(f;[\alpha,\beta])/(\beta-\alpha)+F_{n}(f;[\alpha,\beta])/(2n_i-2)} \le \tau_{[\alpha,\beta]}\\
\end{align*}

And by \eqref{fdoubprimenorm}, we obtain
$$\norm[{[\alpha,\beta]}]{f-A_{n}(f;[\alpha,\beta])} \le  \frac{\tau_{[\alpha,\beta]}(\beta-\alpha) G_n(f;[\alpha,\beta]) } {4(n-1)(2n-2 -\tau_{[\alpha,\beta]})} =\varepsilon_{[\alpha,\beta]}.$$

Let $\vn=\{n_{[\alpha,\beta]}\}_{[\alpha,\beta] \in \cp}$ denote the number of points. Define
\begin{align*}
&\vA_{\vn}(f;\cp)=\{A_{n_{[\alpha,\beta]}}(f;[\alpha,\beta])\}_{[\alpha,\beta] \in \cp} \\
 &\vG_{\vn}(f;\cp)=\{G_{n_{[\alpha,\beta]}}(f;[\alpha,\beta])\}_{[\alpha,\beta] \in \cp} \\
&\vF_{\vn}(f;\cp)=\{F_{n_{[\alpha,\beta]}}(f;[\alpha,\beta])\}_{[\alpha,\beta] \in \cp} \\
\end{align*}

For simplification, we can denote
$$\tau_{[t_{l-1},t_l]}=\tau_l,\qquad n_{[t_{l-1},t_l]}=n_l, \qquad  \varepsilon_{[t_{l-1},t_l]}=\varepsilon_l, \qquad l=1,\ldots,L$$
where $L=|\cp|$ is the cardinality of $\cp$.
%Therefore,
%\begin{align*}
%\norm[\infty]{f-A_{n}(f;[\alpha,\beta])}
%& \le \frac{(\beta-\alpha)^2}{8(n-1)^2}\norm[\infty]{f''}, \\
%& \le \frac{(\beta-\alpha)^2}{8(n-1)^2}\cdot\frac{\tau(\vol([\alpha,\beta]))G_n(f;[\alpha,\beta])}{1-\tau(\vol([\alpha,\beta]))(\beta-\alpha)/(2n-2)} \\
%& \le \frac{\tau(\vol([\alpha,\beta]))(\beta-\alpha)^2 G_n(f;[\alpha,\beta])}{4(n-1)(2n-2-\tau(\vol([\alpha,\beta]))(\beta-\alpha))}=\varepsilon_{[\alpha,\beta]}.
%\end{align*}



%Then we know, for a partition $\cp$, we have
%\begin{align*}
%& \Phi(\tvS_{\cp};\cp) = \tPhi(\tvS_{\cp},\veps_{\cp};\cp) = \sum_{l=1}^L  A_{n_{l}^{(L)}}(\cdot; [t_{l-1},t_l]), \\
%&\err(\tvS_{\cp},\veps_{\cp};\cp) = \norm[\infty]{\veps_{\cp}}=\max_{l=1,\ldots,L}\varepsilon_{[t_{l-1},t_l]},
%\end{align*}
%where $L=\abs{\cp}.$


\begin{algo}[Locally Adaptive Univariate Function Recovery] \label{multistageapproalgo}
Let the sequence of algorithms $\{\vA_{\vn}(\cdot;\cp)\}$, $\{\vG_{\vn}(\cdot;\cp)\}$,  $\{\vF_{\vn}(\cdot;\cp)\}$, and $\vn, \cp, a, b$  be as described above. Set $L=1$.
Choose integer $\tau_{\lo}, \tau_{\text{hi}}$, where $\tau_{\text{hi}} \ge \tau_{\lo}$ such that
$$\tau_1 = \max\left\{  \tau_{\text{hi}} \left(\frac{\tau_{\lo}}{\tau_{\text{hi}}}\right)^{\frac{1}{1+b-a}}  ,3\right\}.$$
Then let $n_1= \left\lceil\frac{\tau_1+1}{2}  \right\rceil+1, \ \varepsilon_1=\infty.$ For any error tolerance $\varepsilon$ and input function $f$, do the following:
\begin{description}
\item[Stage 1.\ Find the maximum error] If $\max\limits_{l=1,\ldots,L}\varepsilon_l < \varepsilon,$ stop.
Otherwise, find
$$k = \arg\max\limits_{l=1,\ldots,L}\varepsilon_l.$$
\item[Stage 2.\ Compute{$\norm[{[t_{k-1},t_k]}]{f'-\frac{f(t_k)-f(t_{k-1})}{t_k-t_{k-1}}}$} and bound {$\norm[{[t_{k-1},t_k]}]{f''}$}.] Compute $G_{n_k}(f;{[t_{k-1},t_k]})$ in \eqref{estfirstderiv} and $F_{n_k}(f;{[t_{k-1},t_k]})$ in \eqref{Fnormappxalg}.
\item[Stage 3. Check the necessary condition for $f \in \cc_{\tau_k}$.] Compute
    \begin{align*}
     \tau_{\min,n_k} =  \frac{F_{n_k}(f;{[t_{k-1},t_k]})}{G_{n_k}(f;{[t_{k-1},t_k]})/(t_k-t_{k-1})+F_{n_k}(f;{[t_{k-1},t_k]})/(2n_k-2)}.
    \end{align*}
If $\tau_k \ge \tau_{\min,n_k}$, then go to stage 4.  Otherwise, set $\tau_k = 2\tau_k$.  If $n_k \ge (\tau_k+1)/2$, then go to stage 4.  Otherwise, go to Stage 5.
\item[Stage 4. Check for convergence.] Estimate $\varepsilon_k.$
$$\varepsilon_k=\frac{\tau_k(t_k-t_{k-1})G_{n_k}(f)}{4(n_k-1)(2n_k-2 - \tau_k)}.$$
If $\varepsilon_k < \varepsilon ,$ go to Stage 1. Otherwise go to Stage 5.
\item[Stage 5.\ Double the initial number of points and split the interval]
Let $L=L+1.$ Then
\begin{align*}
t_l=t_{l-1}, \qquad \ n_l&=n_{l-1}, \qquad \varepsilon_l=\varepsilon_{l-1}, \qquad \tau_l=\tau_{l-1}, \qquad \text{ when } k < l \le L,\\
t_k&=\frac{t_{k-1}+t_k}{2}, \qquad \varepsilon_k=\varepsilon_{k+1}=\infty, \\
&  \tau_k=\tau_{k+1}=\max\left\{ \tau_{\text{hi}} \left(\frac{\tau_{\lo}}{\tau_{\text{hi}}}\right)^{\frac{1}{1+t_k-t_{k-1}}}  ,3\right\}.
\end{align*}
Go to Stage 1.
\end{description}
\end{algo}

%\begin{theorem} \label{multistageappxthm}
%Let $\sigma >0$ be some fixed parameter, and let $\cb_{\sigma}=\{f \in  \mathcal{W}^{2,\infty} : \norm[\infty]{f''}\leq \sigma\}$. Let $A \in \ca(\cb_{\sigma}, \cl_{\infty}, \APP, \Lambda^{\std})$ be the non-adaptive linear spline defined by Algorithm \ref{nonadaptalgo}, and let $\varepsilon>0$ be the error tolerance. Then this algorithm succeeds for $f \in \cb_{\sigma}$, i.e., $\norm[\infty]{f - A(f,\varepsilon)} \le \varepsilon$, and the cost of this algorithm is $\left \lceil \sqrt{\sigma/(8\varepsilon)}\right \rceil + 1$, regardless of the size of $\norm[\infty]{f''}$.
%
%Let $A \in \ca(\cc_{\tau}, \cl_{\infty}, \APP, \Lambda^{\std})$ be the adaptive linear spline defined by Algorithm \ref{multistageapproalgo}, and let $\tau$, $n_1$, and $\varepsilon$ be the inputs and parameters described there. Let $\cc_\tau$ be the cone of functions defined in \eqref{coneappxdef}.  Then it follows that Algorithm \ref{multistageapproalgo} is successful for all functions in $\cc_{\tau}$,  i.e.,  $\norm[\infty]{f - A(f,\varepsilon)} \le \varepsilon$.  Moreover, the cost of this algorithm is bounded below and above as follows:
%\begin{multline}
%\max \left(\left \lceil\frac{\tau+1}{2} \right \rceil, \left \lceil \sqrt{\frac{(b-a)^2 \norm[\infty]{f''}}{8\varepsilon}} \right \rceil \right) +1 \\
%\le \max \left(\left \lceil\frac{\tau+1}{2} \right \rceil, \left \lceil \sqrt{\frac{\tau (b-a) \norm[\infty]{f'-
%\frac{f(b)-f(a)}{b-a}}}{8\varepsilon}} \right \rceil \right) +1 \\
%\le
%\cost(A,f;\varepsilon) \\
%\le \sqrt{\frac{\tau (b-a)  \norm[\infty]{f'-\frac{f(b)-f(a)}{b-a}}}{2\varepsilon}} + \tau + 4
%\le \sqrt{\frac{\tau (b-a)^2\norm[\infty]{f''} }{4\varepsilon}} + \tau + 4.
%\end{multline}
%The algorithm is computationally stable, meaning that the minimum and maximum costs for all integrands, $f$, with fixed $\norm[\infty]{f'-\frac{f(b)-f(a)}{b-a}}$ or $\norm[\infty]{f''}$ are an $\varepsilon$-independent constant of each other.
%\end{theorem}
%


\begin{theorem} \label{multistageappxthm}
Let $\{\vA(\cdot;\cp)\}$ be the adaptive linear spline defined by Algorithm \ref{multistageapproalgo}, and let $\cp$, $\vtau_{\cp}$, and $\varepsilon$ be the inputs and parameters described there and $L=|\cp|$. Let $\cc_{\vtau}$ be the cone of functions defined in \eqref{coneappxdef}.  Then it follows that Algorithm \ref{multistageapproalgo} is successful for all functions in $\cc_{\vtau}$,  i.e.,  $\norm[\infty]{f - \vA(f,\varepsilon;\cp)} \le \varepsilon$.  Moreover, the cost of this algorithm is bounded below and above as follows:
\begin{multline}
%\max \left(\left \lceil\frac{\tau+1}{2} \right \rceil, \left \lceil \sqrt{\frac{(b-a)^2 \norm[\infty]{f''}}{8\varepsilon}} \right \rceil \right) +1 \\
%\le \max \left(\left \lceil\frac{\tau+1}{2} \right \rceil, \left \lceil \sqrt{\frac{\tau (b-a) \norm[\infty]{f'-
%\frac{f(b)-f(a)}{b-a}}}{8\varepsilon}} \right \rceil \right) +1 \\
%\le
\cost(\vA,f;\cp,\varepsilon) \\
\le \sqrt{\frac{1}{2\varepsilon}}\sum\limits_{k=1}^{L}\sqrt{\tau_k(t_k-t_{k-1})\norm[{[t_{k-1},t_k]}]{f'-\frac{f(t_k)-f(t_{k-1})}{t_k-t_{k-1}}}}+\norm[1]{\vtau}+4L
\\
\le \sqrt{\frac{1}{4\varepsilon}}\sum\limits_{k=1}^{L}\sqrt{\tau_k(t_k-t_{k-1})^2\norm[{[t_{k-1},t_k]}]{f''}}+\norm[1]{\vtau}+4L
 \end{multline}

The algorithm is computationally stable, meaning that maximum costs for all functions, $f$, with fixed $\norm[\infty]{f''}$ are an $\varepsilon$-independent constant of each other.
\end{theorem}
\begin{proof}
At first, we would like to prove $L$, the cardinality of $\cp$ is bounded.

According to our algorithm, we know the length of each subinterval $$t_k-t_{k-1}=\left(\frac{1}{2}\right)^{m_k}(b-a),$$ where $m_k \in \mathbb{N}$.
And for each subinterval $[t_{k-1},t_k] \subset \cp$, we have the same number of points $n_k$ and a fixed $\tau_k$. Then we know
$$\frac{\tau_k(t_k-t_{k-1}) G_{n_k}(f;[t_{k-1},t_k]) } {4(n_k-1)(2n_k-2 -\tau_k)} \le \varepsilon \Leftrightarrow 
\frac{\tau_k \left(\frac{1}{2}\right)^{m_k}(b-a) G_{n_k}(f;[t_{k-1},t_k]) } {4(n_k-1)(2n_k-2 -\tau_k)} \le \varepsilon.$$
And we know 
$$\frac{\tau_k\left(\frac{1}{2}\right)^{m_k}(b-a)  G_{n_k}(f;[t_{k-1},t_k]) } {4(n_k-1)(2n_k-2 -\tau_k)} 
\le \frac{\tau_k\left(\frac{1}{2}\right)^{2m_k}(b-a)^2 \norm[{[t_{k-1},t_k]}]{f''} }{8(n_k-1)(2n_k-2 -\tau_k)} \le \varepsilon.$$
Hence, we know
$$m_k \ge \frac{1}{2}\frac{\log{\frac{8\varepsilon(n_k-1)(2n_k-2 -\tau_k)}{\tau_k(b-a)^2 \norm[{[t_{k-1},t_k]}]{f''}}}}{\log{\frac{1}{2}}}
=\frac{1}{2}\frac{\log{\frac{\tau_k(b-a)^2 \norm[{[t_{k-1},t_k]}]{f''}}{8\varepsilon(n_k-1)(2n_k-2 -\tau_k)}}}{\log{2}}.$$
Then we can let $m_k=\left\lceil\frac{1}{2}\frac{\log{\frac{\tau_k(b-a)^2 \norm[{[t_{k-1},t_k]}]{f''}}{8\varepsilon(n_k-1)(2n_k-2 -\tau_k)}}}{\log{2}}
\right\rceil$. And as $\norm[{[t_{k-1},t_k]}]{f''}$ is bounded, $n_k$ and $\tau_k$ are fixed, $m_k$ is also bounded.
Suppose $[t_{k-1},t_k]$ is the smallest interval, then $L \le 2^{m_k} $ is also bounded.\\

Next, we investigate the cost of our algorithm.
For each subinterval $[t_{k-1},t_k] \subset \cp,$ we want
$$\frac{\tau_k(t_k-t_{k-1}) G_{n_k}(f;[t_{k-1},t_k]) } {4(n_k-1)(2n_k-2 -\tau_k)} \le \varepsilon.$$
And we know that
\begin{multline*}
\frac{\tau_k(t_k-t_{k-1}) G_{n_k}(f;[t_{k-1},t_k]) } {4(n_k-1)(2n_k-2 -\tau_k)} \\
\le  \frac{\tau_k(t_k-t_{k-1})\norm[{[t_{k-1},t_k]}]{f'-\frac{f(t_k)-f(t_{k-1})}{t_k-t_{k-1}}} }{4(n_k-1)(2n_k-2 -\tau_k)}\\
\le \frac{\tau_k(t_k-t_{k-1})^2 \norm[{[t_{k-1},t_k]}]{f''} }{8(n_k-1)(2n_k-2 -\tau_k)}
\end{multline*}
i.e.
\begin{multline*}
n_k \le \sqrt{\frac{\tau_k (t_k-t_{k-1})\norm[{[t_{k-1},t_k]}]{f'-\frac{f(t_k)-f(t_{k-1})}{t_k-t_{k-1}}} }{2\varepsilon}} + \tau_k + 4\\
\le \sqrt{\frac{\tau_k (t_k-t_{k-1})^2\norm[{[t_{k-1},t_k]}]{f''} }{4\varepsilon}} + \tau_k + 4.
\end{multline*}
Hence,
\begin{multline*}
\cost(\vA,f;\cp,\varepsilon)=\sum\limits_{k=1}^{L}n_k \\
\le \sqrt{\frac{1}{2\varepsilon}}\sum\limits_{k=1}^{L}\sqrt{\tau_k(t_k-t_{k-1})\norm[{[t_{k-1},t_k]}]{f'-\frac{f(t_k)-f(t_{k-1})}{t_k-t_{k-1}}}}+\norm[1]{\vtau}+4L
\\
\le \sqrt{\frac{1}{4\varepsilon}}\sum\limits_{k=1}^{L}\sqrt{\tau_k(t_k-t_{k-1})^2\norm[{[t_{k-1},t_k]}]{f''}}+\norm[1]{\vtau}+4L
\end{multline*}
\end{proof}


\end{document}
